{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.iloc[:,:-3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OA', 'YA'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset['GROUP']\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del values\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12136, 71554)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='GROUP', data=dataset, palette='pastel')\n",
    "plt.title('Aging label distribution')\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    values, labels_encoded, test_size=0.1, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.05, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10375 1214 547\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47151807228915665\n",
      "0.471169686985173\n",
      "0.4716636197440585\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train == 1]) / len(y_train))\n",
    "print(len(y_test[y_test == 1]) / len(y_test))\n",
    "print(len(y_val[y_val == 1]) / len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age distribution is the dataset is almost 50/50. This distribution is maintained in the train, test and validation subset that we have prepared for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def plotSurface(data, title):    \n",
    "    fig = go.Figure(data=[go.Surface(z=data)])\n",
    "    fig.update_traces(\n",
    "        contours_z=dict(\n",
    "            show=True, \n",
    "            usecolormap=True,\n",
    "            highlightcolor=\"limegreen\",\n",
    "            project_z=True\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "            title=title,\n",
    "            autosize=False,\n",
    "            width=700,\n",
    "            height=700,\n",
    "            margin=dict(l=65, r=50, b=65, t=90),\n",
    "            scene=dict(\n",
    "            xaxis=dict(\n",
    "                title='Time (sample num)',\n",
    "                gridcolor='rgb(255, 255, 255)',\n",
    "                # erolinecolor='rgb(255, 255, 255)',\n",
    "                showbackground=True,\n",
    "                backgroundcolor='rgb(230, 230,230)'\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Channel',\n",
    "                # tickvals=channels,\n",
    "                # ticktext=sensor_positions,\n",
    "                gridcolor='rgb(255, 255, 255)',\n",
    "                zerolinecolor='rgb(255, 255, 255)',\n",
    "                showbackground=True,\n",
    "                backgroundcolor='rgb(230, 230, 230)'\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                title='Sensor Value',\n",
    "                gridcolor='rgb(255, 255, 255)',\n",
    "                zerolinecolor='rgb(255, 255, 255)',\n",
    "                showbackground=True,\n",
    "                backgroundcolor='rgb(230, 230,230)'\n",
    "            ),\n",
    "            aspectratio = dict(x=1, y=1, z=0.5),\n",
    "            aspectmode = 'manual'\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def plot_trial_subject(i):\n",
    "    subj_inf = dataset.index[i].split('_')\n",
    "    subj = subj_inf[0]\n",
    "    trial = subj_inf[1]\n",
    "    stimulus = subj_inf[2]\n",
    "    sample = dataset.iloc[i][:-3].values.reshape(133, 538)\n",
    "\n",
    "    plotSurface(sample, 'Channels values in trial ' + trial + ' for subject ' + subj + '. Stimulus type ' + stimulus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Age group experiments\n",
    "\n",
    "Let's try different supervised models to find the best accuracy labeling the age group.\n",
    "\n",
    "### 1.1 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Perceptron(\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913509060955519"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140767824497258"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 1 Hiden Layer Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324546952224053"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177330895795247"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 3 Hidden Layers Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,100),\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415156507413509"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195612431444241"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below compares the accuracy for each of our models when labeling the subjects by age group. We see how this measure is pretty equal for all of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>validation set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.913509</td>\n",
       "      <td>0.914077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Hidden Layer</th>\n",
       "      <td>0.932455</td>\n",
       "      <td>0.917733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Hidden Layers</th>\n",
       "      <td>0.941516</td>\n",
       "      <td>0.919561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test set  validation set\n",
       "Perceptron      0.913509        0.914077\n",
       "1Hidden Layer   0.932455        0.917733\n",
       "3Hidden Layers  0.941516        0.919561"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_results = [[0.913509060955519, 0.9140767824497258], [0.9324546952224053, 0.9177330895795247], [0.9415156507413509, 0.9195612431444241]]\n",
    "pd.DataFrame(\n",
    "    data=pca_results,\n",
    "    index=['Perceptron','1Hidden Layer','3Hidden Layers'],\n",
    "    columns=['Test set', 'validation set']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Excluding subjects for cross validation\n",
    "\n",
    "We are getting a really good accuracy in the first try, what looks too optimistic. This can point out that our models are biased by subjects. We are going to exclude some subjects from our training/test sets and try to validate our models with those subjects that aren't include in our initial sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subjects = ('O200_', 'O201_', 'O204_', 'O205_', 'O206_', 'Y100_', 'Y101_', 'Y104_', 'Y105_', 'Y107_', 'Y108_')\n",
    "train_subjects = dataset[~dataset.index.str.startswith(val_subjects)]\n",
    "val_subjects = dataset[dataset.index.str.startswith(val_subjects)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our train/test and validation sets don't share any subject in their samples, so we can confirm our model aren't learning subjects patterns but they learn group patterns instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OA', 'YA'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = train_subjects.iloc[:,:-3].values\n",
    "labels = train_subjects['GROUP']\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    values, labels_encoded, test_size=0.1, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "X_val = val_subjects.iloc[:,:-3].values\n",
    "y_val = label_encoder.fit_transform(val_subjects['GROUP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9174 1020 1942\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have increased the number of samples in our validations sets to increase get a better confidence in our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Perceptron(\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9309989701338826"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 1 Hiden Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343137254901961"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937178166838311"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 3 Hiden Layers Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,100),\n",
    "    max_iter=500,\n",
    "    alpha=0.0001,\n",
    "    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, random_state=21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009803921568628"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927394438722966"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how our models maintain a good accuracy for the cross validation experiments excluding subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard</th>\n",
       "      <th>Excluding Subjs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Hidden Layer</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Hidden Layers</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Standard  Excluding Subjs\n",
       "Perceptron         0.914            0.931\n",
       "1Hidden Layer      0.918            0.937\n",
       "3Hidden Layers     0.920            0.927"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_results = [[0.914, 0.931], [0.918, 0.937], [0.920, 0.927]]\n",
    "pd.DataFrame(\n",
    "    data=pca_results,\n",
    "    index=['Perceptron','1Hidden Layer','3Hidden Layers'],\n",
    "    columns=['Standard', 'Excluding Subjs']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.4 Finding best tunning\n",
    "\n",
    "Let's try to improve our accuracy finding the best tunning parameter for our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subjects = ('O200_', 'O201_', 'O204_', 'O205_', 'O206_', 'O207_', 'O208_',\n",
    "                'Y100_', 'Y101_', 'Y104_', 'Y105_', 'Y107_', 'Y108_', 'Y109_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset[~dataset.index.str.startswith(test_subjects)]\n",
    "test_set = dataset[dataset.index.str.startswith(test_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OA', 'YA'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_set['GROUP']\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:-3].values\n",
    "y_train = label_encoder.fit_transform(train_set['GROUP'])\n",
    "X_test = test_set.iloc[:,:-3].values\n",
    "y_test = label_encoder.fit_transform(test_set['GROUP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9608 9608 2528 2528\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "del train_set\n",
    "del test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,100),\n",
    "    max_iter=500,\n",
    "    random_state=21)\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': np.logspace(-4, 0, 6),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameter_space, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,100),\n",
    "    max_iter=500,\n",
    "    random_state=21,\n",
    "    alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9588607594936709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(\n",
    "    max_iter=500,\n",
    "    random_state=21)\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': np.logspace(-4, 0, 6),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameter_space, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347310126582279"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(\n",
    "    alpha=0.0001,\n",
    "    max_iter=500,\n",
    "    random_state=21)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620253164556962"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.5 Best accuracy for each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = list(dataset.index.map(lambda x: x.split('_')[0]))\n",
    "o_subjects = list(dict.fromkeys(element for element in subjects if element[0] == 'O'))\n",
    "y_subjects = list(dict.fromkeys(element for element in subjects if element[0] == 'Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks_split(items, size):\n",
    "    chunks = [] \n",
    "    \n",
    "    for i in range(0, len(items), size):\n",
    "        chunks.append(items[i:i + size])\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def avg_accuracy(method):\n",
    "    accuracy = []\n",
    "\n",
    "    o_chunks = chunks_split(o_subjects, 6)\n",
    "    y_chunks = chunks_split(y_subjects, 5)\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        subjects = tuple(o_chunks[i] + y_chunks[i])\n",
    "        \n",
    "        print(subjects)\n",
    "        \n",
    "        train_set = dataset[~dataset.index.str.startswith(subjects)]\n",
    "        test_set = dataset[dataset.index.str.startswith(subjects)]\n",
    "\n",
    "        X_train = train_set.iloc[:,:-3].values\n",
    "        y_train = label_encoder.fit_transform(train_set['GROUP'])\n",
    "        X_test = test_set.iloc[:,:-3].values\n",
    "        y_test = label_encoder.fit_transform(test_set['GROUP'])\n",
    "\n",
    "        del train_set\n",
    "        del test_set\n",
    "        \n",
    "        if(method == 'regression'):\n",
    "            clf = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy.append(accuracy_score(y_test, y_pred))\n",
    "            \n",
    "        elif(method == 'perceptron'):\n",
    "            clf = Perceptron(\n",
    "                alpha=0.0001,\n",
    "                max_iter=500,\n",
    "                random_state=21).fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy.append(accuracy_score(y_test, y_pred))\n",
    "            \n",
    "        elif(method == 'multilayer'):\n",
    "            clf = MLPClassifier(\n",
    "                hidden_layer_sizes=(100,100,100),\n",
    "                max_iter=500,\n",
    "                random_state=21,\n",
    "                alpha=1).fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    return sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O213', 'O236', 'O207', 'O235', 'O220', 'O218', 'Y124', 'Y115', 'Y128', 'Y119', 'Y132')\n",
      "('O204', 'O211', 'O229', 'O224', 'O230', 'O201', 'Y127', 'Y123', 'Y102', 'Y109', 'Y105')\n",
      "('O226', 'O233', 'O217', 'O202', 'O237', 'O206', 'Y117', 'Y122', 'Y131', 'Y100', 'Y110')\n",
      "('O223', 'O212', 'O222', 'O200', 'O225', 'O214', 'Y114', 'Y121', 'Y129', 'Y108', 'Y120')\n",
      "('O228', 'O219', 'O208', 'O216', 'O227', 'O232', 'Y101', 'Y133', 'Y104', 'Y111', 'Y125')\n"
     ]
    }
   ],
   "source": [
    "regression_avg_accuracy = avg_accuracy('regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905177150035229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O213', 'O236', 'O207', 'O235', 'O220', 'O218', 'Y124', 'Y115', 'Y128', 'Y119', 'Y132')\n",
      "('O204', 'O211', 'O229', 'O224', 'O230', 'O201', 'Y127', 'Y123', 'Y102', 'Y109', 'Y105')\n",
      "('O226', 'O233', 'O217', 'O202', 'O237', 'O206', 'Y117', 'Y122', 'Y131', 'Y100', 'Y110')\n",
      "('O223', 'O212', 'O222', 'O200', 'O225', 'O214', 'Y114', 'Y121', 'Y129', 'Y108', 'Y120')\n",
      "('O228', 'O219', 'O208', 'O216', 'O227', 'O232', 'Y101', 'Y133', 'Y104', 'Y111', 'Y125')\n"
     ]
    }
   ],
   "source": [
    "perceptron_avg_accuracy = avg_accuracy('perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630540249568883"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O213', 'O236', 'O207', 'O235', 'O220', 'O218', 'Y124', 'Y115', 'Y128', 'Y119', 'Y132')\n",
      "('O204', 'O211', 'O229', 'O224', 'O230', 'O201', 'Y127', 'Y123', 'Y102', 'Y109', 'Y105')\n",
      "('O226', 'O233', 'O217', 'O202', 'O237', 'O206', 'Y117', 'Y122', 'Y131', 'Y100', 'Y110')\n",
      "('O223', 'O212', 'O222', 'O200', 'O225', 'O214', 'Y114', 'Y121', 'Y129', 'Y108', 'Y120')\n",
      "('O228', 'O219', 'O208', 'O216', 'O227', 'O232', 'Y101', 'Y133', 'Y104', 'Y111', 'Y125')\n"
     ]
    }
   ],
   "source": [
    "multilayer_avg_accuracy = avg_accuracy('multilayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014972124694506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilayer_avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below show the best accuracy obtained for each of our model when applying best tunning and cross validation excluding subjects.\n",
    "\n",
    "As we obtained a really good accuracy, so we add experiments with a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.905177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.863054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multilayer</th>\n",
       "      <td>0.901497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cross Validation Accuracy\n",
       "Logistic Regression                   0.905177\n",
       "Perceptron                            0.863054\n",
       "Multilayer                            0.901497"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [0.905177150035229, 0.8630540249568883, 0.9014972124694506]\n",
    "pd.DataFrame(\n",
    "    data=results,\n",
    "    index=['Logistic Regression', 'Perceptron', 'Multilayer'],\n",
    "    columns=['Cross Validation Accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stimulus Type Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def get_encoded_classes(filter_col, value, label_col):\n",
    "    labels = dataset[dataset[filter_col] == value][label_col]\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    label_encoder.classes_\n",
    "    \n",
    "    return labels_encoded\n",
    "    \n",
    "def get_sets(filter_col, value, label_col):\n",
    "    values = dataset[dataset[filter_col] == value].iloc[:,:-3].values\n",
    "    labels_encoded = get_encoded_classes(filter_col, value, label_col)\n",
    "\n",
    "    return train_test_split(\n",
    "        values,\n",
    "        labels_encoded,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=labels_encoded\n",
    "    )\n",
    "\n",
    "def get_accuracy(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    log_reg_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    clf = Perceptron(\n",
    "        alpha=0.0001,\n",
    "        max_iter=500,\n",
    "        random_state=21).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    perceptron_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=(100,100,100),\n",
    "        max_iter=500,\n",
    "        random_state=21,\n",
    "        alpha=0.0006).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    mlayer_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return log_reg_acc, perceptron_acc, mlayer_acc\n",
    "\n",
    "def get_avg_accuracy(X_train, X_test, y_train, y_test):\n",
    "    accuracies = []\n",
    "    labels_set = set(y_train)\n",
    "\n",
    "    for label in labels_set:\n",
    "        accuracies.append(get_accuracy(X_train,\n",
    "                                       X_test,\n",
    "                                       labels_converter(y_train, label, labels_set),\n",
    "                                       labels_converter(y_test, label, labels_set)\n",
    "                                      )\n",
    "                         )\n",
    "        \n",
    "    return np.sum(np.array(accuracies), axis=0)/3\n",
    "\n",
    "def labels_converter(values, label, labels_set):\n",
    "    return list(map(lambda x: x if x == label else len(labels_set), values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [IGNORE] 2.1 Identifying stimulus type for each age group\n",
    "\n",
    "Now we will try to identify whether some of our model is able to identify the stimulus type for each of our age group. We will also compare if the accuracy differ between both groups, what could be interpreted as one of the group is reacting more drastically to each type of stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Identifying stimulus type for the older group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3333333333333333, 0.34735202492211836, 0.34890965732087226)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_data set.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('GROUP', 'OA', 'STIMULUS')\n",
    "del dataset\n",
    "accuracy_stimulus_older = get_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_older)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Identifying stimulus type for the younger group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4013961605584642, 0.37347294938917974, 0.3769633507853403)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('GROUP', 'YA', 'STIMULUS')\n",
    "del dataset\n",
    "accuracy_stimulus_younger = get_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_younger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Perceptron</th>\n",
       "      <th>Multilayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elderly Group</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.347352</td>\n",
       "      <td>0.348910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Group</th>\n",
       "      <td>0.401396</td>\n",
       "      <td>0.373473</td>\n",
       "      <td>0.376963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Logistic Regression  Perceptron  Multilayer\n",
       "Elderly Group             0.333333    0.347352    0.348910\n",
       "Young Group               0.401396    0.373473    0.376963"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [accuracy_stimulus_older, accuracy_stimulus_younger]\n",
    "pd.DataFrame(\n",
    "    data=results,\n",
    "    index=['Elderly Group','Young Group'],\n",
    "    columns=['Logistic Regression', 'Perceptron', 'Multilayer']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Identifying stimulus type for each age group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.0 Finding best tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('GROUP', 'OA', 'STIMULUS')\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set = list(set(y_train))\n",
    "y_train = labels_converter(y_train, labels_set[0], labels_set)\n",
    "y_test = labels_converter(y_test, labels_set[0], labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.000630957344480193}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,100),\n",
    "    max_iter=500,\n",
    "    random_state=21)\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': np.logspace(-4, 0, 6),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameter_space, cv=3)\n",
    "grid = grid_search.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(\n",
    "    max_iter=500,\n",
    "    random_state=21)\n",
    "\n",
    "parameter_space = {\n",
    "    'alpha': np.logspace(-4, 0, 6),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameter_space, cv=3)\n",
    "grid = grid_search.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Identifying stimulus type for the older group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57320872 0.54465213 0.58307373]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('GROUP', 'OA', 'STIMULUS')\n",
    "del dataset\n",
    "accuracy_stimulus_older = get_avg_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_older)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Identifying stimulus type for the younger group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60267597 0.5945317  0.62361838]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('GROUP', 'YA', 'STIMULUS')\n",
    "del dataset\n",
    "accuracy_stimulus_younger = get_avg_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_younger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Perceptron</th>\n",
       "      <th>Multilayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elderly Group</th>\n",
       "      <td>0.573209</td>\n",
       "      <td>0.544652</td>\n",
       "      <td>0.583074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Group</th>\n",
       "      <td>0.602676</td>\n",
       "      <td>0.594532</td>\n",
       "      <td>0.623618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Logistic Regression  Perceptron  Multilayer\n",
       "Elderly Group             0.573209    0.544652    0.583074\n",
       "Young Group               0.602676    0.594532    0.623618"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [accuracy_stimulus_older, accuracy_stimulus_younger]\n",
    "pd.DataFrame(\n",
    "    data=results,\n",
    "    index=['Elderly Group','Young Group'],\n",
    "    columns=['Logistic Regression', 'Perceptron', 'Multilayer']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above we see how the accuracy of our models identifying the type of stimulus is really low. The models assign the stimulus type labels randomly for both age groups. \n",
    "\n",
    "This can point out that the type of stimulus aren't reflected in the EEG data that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Identifying age group for each stimulus type\n",
    "\n",
    "We also want to identify whether the age groups are easier to identify for any of the stimulus type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Identify age groups for positive stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.922879177377892, 0.8740359897172236, 0.9023136246786633)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('STIMULUS', 'POSITIVE', 'GROUP')\n",
    "del dataset\n",
    "accuracy_stimulus_positive = get_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Identify age groups for neutral stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9359605911330049, 0.9137931034482759, 0.9211822660098522)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('STIMULUS', 'NEUTRAL', 'GROUP')\n",
    "del dataset\n",
    "accuracy_stimulus_neutral = get_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Identify age groups for negative stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9333333333333333, 0.8928571428571429, 0.9)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('datasets/full_dataset.pkl')\n",
    "X_train, X_test, y_train, y_test = get_sets('STIMULUS', 'NEGATIVE', 'GROUP')\n",
    "del dataset\n",
    "accuracy_stimulus_negative = get_accuracy(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_stimulus_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Perceptron</th>\n",
       "      <th>Multilayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>0.922879</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.902314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.921182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Perceptron  Multilayer\n",
       "Positive              0.922879    0.874036    0.902314\n",
       "Neutral               0.935961    0.913793    0.921182\n",
       " Negative             0.933333    0.892857    0.900000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [accuracy_stimulus_positive, accuracy_stimulus_neutral, accuracy_stimulus_negative]\n",
    "pd.DataFrame(\n",
    "    data=results,\n",
    "    index=['Positive','Neutral', ' Negative'],\n",
    "    columns=['Logistic Regression', 'Perceptron', 'Multilayer']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the table above that the accuracy of our models indetifying the age group doesn't significantly change between the different stimulus type. So we can conclude that the reaction of older and younger subjects are similar between stimulus type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
